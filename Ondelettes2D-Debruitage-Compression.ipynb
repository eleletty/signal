{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformée en Ondelettes 2D, application au traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_endpoint_url = 'https://object-rook-ceph.apps.math.cnrs.fr/'\n",
    "s3_access_key_id = '9F7EB8YBUWXDV7A4IZYW' # le contenu de secrets/dossal\n",
    "s3_secret_access_key = 'skV01Eei5M3xVOxROIDr3qymYhWtkrxPpMyj8nwb' # le contenu de secrets/dossal\n",
    "s3_bucket = 'signal-image'\n",
    "s3 = boto3.client('s3',\n",
    "                  '',\n",
    "                  endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)\n",
    "Data=[\"Lenna.jpg\",\"Canaletto.jpeg\",\"MinotaureBruite.jpeg\",\"Cartoon.jpg\"]\n",
    "if not os.path.isfile('Lenna.jpg'):\n",
    "    for filenames in Data:  \n",
    "        s3.download_file(s3_bucket,filenames,filenames)\n",
    "def chargeData(name):\n",
    "    if name=='Lenna':\n",
    "        res=np.array(Image.open(\"Lenna.jpg\")).astype(float)\n",
    "    if name=='Canaletto':\n",
    "        res=np.array(Image.open(\"Canaletto.jpeg\")).astype(float)\n",
    "    if name=='Minotaure':\n",
    "        res=np.array(Image.open(\"MinotaureBruite.jpeg\")).astype(float)  \n",
    "    if name=='Cartoon':\n",
    "        res=np.array(Image.open(\"Cartoon.jpg\")).astype(float) \n",
    "    return res\n",
    "options1=dict(width=400,height=400,xaxis=None,yaxis=None,toolbar=None)\n",
    "options2=dict(width=700,height=400,xaxis=None,yaxis=None,toolbar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation linéaire et non linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im2=chargeData('Lenna')\n",
    "im=chargeData('Canaletto')\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size=400\n",
    "WT= pywt.wavedecn(im, 'haar', mode='per', level=2)\n",
    "arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "hv.Image(arr).opts(cmap='gray',width=size,height=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approxiamtion non linéaire en seuillant les coefficients d'ondelettes.\n",
    "On pourra utiliser les fonctions suivante : pywt.coeffs_to_array et pywt.array_to_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SeuillageOndelette(SB,qmf,L,Seuil):\n",
    "        WTB= pywt.wavedecn(SB, qmf, mode='per', level=L) #on décompose le signal en coeff\n",
    "        arr, coeff_slices = pywt.coeffs_to_array(WTB) #on place les coeff dans un tabl\n",
    "        \n",
    "        WTS = arr*(np.abs(arr)>Seuil) + Seuil *(np.abs(arr)<Seuil) #on impose une condition sur un seuil choisi\n",
    "        ncoeffs=len(WTS)\n",
    "        coeffs_from_arr = pywt.array_to_coeffs(WTS, coeff_slices) # on ne garde que les coeff sup à ce seuil\n",
    "        Srec=pywt.waverecn(coeffs_from_arr,qmf,mode='per') #on recompose le signal avec seulement les coeff sélectionnés\n",
    "        return Srec,ncoeffs\n",
    "\n",
    "\n",
    "def ApproxOnd2D(S, qmf, L, threshold): \n",
    "    rows, cols = S.shape\n",
    "    Lmax_rows = pywt.dwt_max_level(rows, pywt.Wavelet(qmf).dec_len) #calcul du niveau maximal de décomposition du signal possible\n",
    "    L1 = min(L, Lmax_rows) #pour ne pas avoir un trop gros niveau de décomposition on prend le min entre Lmax ci-dessus et un L arbitrairement choisi\n",
    "    Srec,ncoeffs=SeuillageOndelette(S,qmf,L1,threshold) #on applique le seuillage dur avec le niveau de décomposition choisi au-dessus\n",
    "    return Srec, ncoeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le seuillage effectué ici est appelé seuillage doux. Il affecte la valeur d'un seuil à tous les pixels de l'image en dessous de ce seuil. Cela permet d'avoir une reconstruction assez 'continue' du signal tout en gardant les valeurs des pixels les plus importantes !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s=10\n",
    "#s=25\n",
    "#s=50\n",
    "L=6\n",
    "Irec,p=ApproxOnd2D(im,'db2',L,s)\n",
    "#On remarque qu'à Seuil=10 cela marche très bien\n",
    "#Cependant si le Seuil est trop grand (par exemple plus de 50) on a beaucoup de pixel valant 0 pour la reconstruction\n",
    "hv.Image(Irec).opts(cmap='gray',width=400,height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une focntion PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    mse = np.mean( (Iref - I) ** 2 ) #on calcule l'erreur moyenne entre une image de référence et une autre image (souvent reconstruite ou bruitée) \n",
    "    if mse == 0: #si c'est la même image on renvoit PSNR = 100\n",
    "        return 100\n",
    "    Val_MAX = np.max(Iref) #sinon on récupérer le max de Iref et on applique la formule du PSNR\n",
    "    return 20 * np.log10(Val_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approximation non linéaire en conservant un nombre N de coefficients d'ondelettes et la tester. On pourra utiliser les fonctions pywt.ravel_coeffs et unravel_coeffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ApproxOnd2nonlin(I,qmf,L,N):\n",
    "    #on fait de même que pour le seuillage dur\n",
    "    rows, cols = I.shape\n",
    "    Lmax_rows = pywt.dwt_max_level(rows, pywt.Wavelet(qmf).dec_len)\n",
    "    L1 = min(L,Lmax_rows)\n",
    "    WT = pywt.wavedecn(I, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WT)\n",
    "    \n",
    "    Ind = np.argsort(np.abs(arr)) #on trie les valeurs absolues par ordre croissant et on récupère les indices ordonnés dans Ind\n",
    "    \n",
    "    WTS = np.zeros_like(arr)\n",
    "    WTS[Ind[-N:]] = arr[Ind[-N:]]  #on garde les N coeffs les plus grands\n",
    "    \n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices, coeff_shapes)\n",
    "    Irec = pywt.waverecn(coeffs_from_arr, qmf, mode='per')\n",
    "    \n",
    "    p = PSNR(Irec, I) #on vérifie la quamlité de la reconstruction de l'image en affichant le PSNR\n",
    "    return Irec, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N=20000 #le nombre de coeffs à garder plus il est grand mieux c'est !\n",
    "Irec,p=ApproxOnd2nonlin(im,'db2',L,N)\n",
    "hv.Image(Irec).opts(title=f'Image reconstruite, PSNR={p:.2f}', cmap='gray',width=400,height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un Dashboard qui permet d'explorer la fonction précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Créer la classe Approx2D pour mieux visualiser l'impact des différents paramètres sur notre fonction\n",
    "wavelist = ['db2','db3','db4','coif1','coif2','coif3']\n",
    "\n",
    "class Approx2D(param.Parameterized):\n",
    "    #on crée les références de chaque paramètres qu'on veut utiliser\n",
    "    #on définit à chaque fois la valeur de défaut du paramètre et les différentes modalités/valeurs qu'il peut prendre dans notre dashboard\n",
    "    Image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    qmf = param.ObjectSelector(default=\"db2\", objects=wavelist)\n",
    "    L = param.Integer(5, bounds=(0,7))\n",
    "    N = param.Integer(2000, bounds=(1, 10000))\n",
    "\n",
    "    def view(self):\n",
    "        I=imagesRef[self.Image]\n",
    "\n",
    "        Irec, p = ApproxOnd2nonlin(I, self.qmf, self.L, self.N)\n",
    "\n",
    "        return pn.Row(hv.Image(I).opts(title=f'Image de référence',cmap='gray'),\n",
    "                      hv.Image(Irec).opts(title=f'Image reconstruite, PSNR={p:.2f}', cmap='gray')) \n",
    "    #pour afficher l'image reconstruite et le PSNR par rapport à l'image de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx2D = Approx2D()\n",
    "pn.Row(approx2D.param,approx2D.view) #pour afficher le dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :** \n",
    "On remarque que plus on garde de coeffs meilleur est la reconstruction. De plus si on met un L, donc le niveau de décomposition, trop faible (c'est à dire inférieur à 3) notre reconstruction est également mauvaise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'experiences qui permet d'explorer la fonction ApproxOnd2nonlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#On crée un plan d'expériences pour ne pas à avoir à recompiler notre fonction \"ApproxOnd2nonlin\" à chaque modification de paramètres\n",
    "#Ainsi on met dans un tableau différentes valeurs de paramètres à tester et on y applique la fonction \"ApproxOnd2nonlin\"\n",
    "import itertools\n",
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences = {'Image':imagesRef,'N':np.linspace(1000,50000,40, dtype='int'), 'level' : range(1,7), 'wave':wavelist}\n",
    "dfexp=pd.DataFrame(list(itertools.product(*experiences.values())),columns=experiences.keys())\n",
    "#on applique la fonction et on récupère le résultat dans une nouvelle colonne\n",
    "dfexp['Result'] = dfexp.apply(lambda row : ApproxOnd2nonlin(imagesRef[row[\"Image\"]],row[\"wave\"],row[\"level\"],row[\"N\"]),axis=1)\n",
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la fonction qui à une ligne de la base de donnée précédente calcule le PSNR associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR(row): #on crée une fonction pour récupérer le PSNR dans la colonne résultat de chaque line\n",
    "    return row[\"Result\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer la fonction sur la base de donnée et ajouter la colonne PSNR à la base de données dfexp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp['PSNR'] = dfexp.apply(lambda row : row2PSNR(row), axis = 1)\n",
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "h = HoverTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#on affiche le PSNR en fonction du nombre de coefficients qu'on garde pour chaque base d'ondelettes.\n",
    "dfexp.hvplot('N','PSNR', by='wave',kind='scatter',groupby=['Image','level']).opts(width=600,tools=[h]).redim.range(PSNR=(0,80),N=(0,50000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "On peut donc chercher la base d'ondelettes la plus optimale, c'est à dire celle qui a le PSNR le plus grand en fonction de nombre de coeffs N qu'on veut garder et du niveau de décomposition.\n",
    "\n",
    "On remarque que pour L=3 c'est coif3 la meilleure base d'ondelettes quelque soit le nombre de coefficients gardés "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue un seuillage dur en ondelettes et la tester. On pourra utiliser la fonction pywt.ravel_coeffs et on pensera à cliper le résultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "\n",
    "def SeuillageDurOndelettes(S,qmf,L,Seuil): #la différence avec le doux : si <Seuil => on met 0 au lieu de la valeur du Seuil\n",
    "    rows, cols = S.shape\n",
    "    Lmax_rows = pywt.dwt_max_level(rows, pywt.Wavelet(qmf).dec_len)\n",
    "    L1 = min(L, Lmax_rows)\n",
    "    WTB= pywt.wavedecn(S, qmf, mode='per', level=L) #on décompose le signal en coeff\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WTB)\n",
    "    WTS = arr*(np.abs(arr)>Seuil) #on impose une condition sur un seuil choisi\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices, coeff_shapes)\n",
    "    Srec=pywt.waverecn(coeffs_from_arr,qmf,mode='per') #on recompose le signal avec seulement les coeff sélectionnés    \n",
    "    return Srec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le seuillage effectué ici est un seuillage dur. Il met à 0 tous les coefficients qui dépassent un certain seuil. Cela permet de conserver l'amplitude du signal mais la reconstruiction est plus 'discontinue' qu'avec un seuillage doux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construire un dashboard qui permet d'explorer la fonction SeuillageDurOndelettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SeuillageDurOndelettes(imagesRef['Lenna'], 'haar', 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveSeuillage(param.Parameterized): #de même que précédemment on crée un dashboard pour tester l'impact de nos paramètres sur notre fonction de Seuillage Dur\n",
    "    Image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    qmf = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    Seuil = param.Number(10,bounds=(1,1000))\n",
    "    L = param.Integer(5, bounds=(0,7))\n",
    "    def view(self):\n",
    "        I=imagesRef[self.Image]\n",
    "        Irec=SeuillageDurOndelettes(I,self.qmf,self.L,self.Seuil)\n",
    "        return pn.Row(hv.Image(I).opts(title=f'Image de référence',cmap='gray'), #pour afficher l'image de référence à côté de l'image reconstruite\n",
    "                      hv.Image(Irec).opts(title=f'Image reconstruite',cmap='gray')) #pour afficher l'image reconstruite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveseuillage = WaveSeuillage()\n",
    "pn.Row(waveseuillage.param, waveseuillage.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "On remarque que plus le seuil est elevé moins l'image est bien reconstruite, en effet on perds plus de coefficients, dont certains qui sont importants pour l'image, alors qu'avec un seuil petit on garde tous les coefficients important pour cette dernière !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On veut désormais tester nos fonctions avec une image bruitée, donc on crée cette dernière :\n",
    "n1,n2=np.shape(im)\n",
    "B=np.random.randn(n1,n2) # le coeff de bruitage qui est un nombre aléatoire de la taille de votre image\n",
    "sigma=100 # pour augmenter la valeur des bruits\n",
    "ib=im+sigma*B #pour créer l'image bruitée\n",
    "ib=np.clip(ib,0,255)\n",
    "hv.Image(ib).opts(cmap='gray',width=400,height=400) #pour visualiser l'image qu'on vient de bruiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire un dashboard qui permet de visualiser rapidement l'effet d'un débruitage en ondelettes et qui renvoie les images originales, bruitées et débruitées ainsi que les PSNR associés aux images bruitéeset débruitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveDebruit(param.Parameterized): #on crée un dashboard pour voir comment se comporte notre fonction en présence d'une image bruitée\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    qmf = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7)) #niveau de décomposition dans la composition de Haar\n",
    "    Seuil = param.Number(3,bounds=(1,500)) #valeur de seuil pour les fonctions de seuillage\n",
    "    Sigma = param.Number(10,bounds=(1,100)) #pour modifier l'importance des bruits (plus sigma est grand plus les bruits ont une grande valeur)\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self):\n",
    "        np.random.seed(self.seednoise)\n",
    "        I=imagesRef[self.image]\n",
    "        n1,n2=np.shape(I)\n",
    "        B=np.random.randn(n1,n2)\n",
    "        ib=I+self.Sigma*B #pour créer l'image bruitée tout en pouvant modifier le bruit avec le sigma\n",
    "        ib=np.clip(ib,0,255)\n",
    "        \n",
    "        Irec=SeuillageDurOndelettes(ib,self.qmf,self.L,self.Seuil)\n",
    "        #on calcule les PSNRs\n",
    "        PSNR_bruit = PSNR(ib,I)\n",
    "        PSNR_seuil = PSNR(Irec,I)\n",
    "        return pn.Row(hv.Image(ib).opts(title=f'Image bruitée, PSNR={PSNR_bruit:.2f}',cmap='gray'), #on affiche l'image bruitée ainsi que son PSNR avec l'image originelle\n",
    "                      hv.Image(Irec).opts(title=f'Image reconstruite, PSNR={PSNR_seuil:.2f}', cmap='gray')) #on affiche l'image reconstruite ainsi que son PSNR avec l'image originelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wavedebruit = WaveDebruit()\n",
    "pn.Row(wavedebruit.param,wavedebruit.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc que plus le bruit est élevé, ainsi plus sigma est grand, donc les valeurs du bruit sont grandes, moins notre fonction de seuillage fonctionne. En effet, elle a du mal à faire la différence entre les coefficients importants pour la reconstruction de l'image et le strop grandes valeurs de bruit. ALors que pour des plus petits bruits elle se débrouille mieux, les coefficients de l'image étant plus élevés que le bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images et translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise un débruitage avec une moyenne sur des NbT fois NbT translations et la tester. Vérifier le gain en PNSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitTranslation(IB,wave,seuil,NbT): #on inclut la notion de translation\n",
    "    Lmax=pywt.dwt_max_level(len(IB),pywt.Wavelet(wave).dec_len)\n",
    "    ISum=0*IB\n",
    "    P=np.zeros(NbT)\n",
    "    for k in np.arange(0,NbT):\n",
    "        IBtemp=np.roll(IB,k) #roll permet de décaler de k vers la droite les éléments d'un vecteur \n",
    "        Irectemp=SeuillageDurOndelettes(IBtemp,wave,Lmax,seuil) #base d'ondelette sur le signal translaté de k\n",
    "        #la transformée en ondelettes est variante par translation don ça nous permet de recup + d'infos\n",
    "        Irectemp2=np.roll(Irectemp,-k) #signal reconstruit de la base d'ondelettes redécalé de k dans l'autre sens \n",
    "        ISum=ISum+Irectemp2\n",
    "        Irec=ISum/(k+1)\n",
    "        P[k]=PSNR(IB,Irec)\n",
    "    return Irec #,P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dasboard pour explorer la fonction précédente. La sortie doit aussi être composée de 3 images et 2 PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debruit_translat(param.Parameterized): #de même que pour les dahsboards prédécents.\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    NbT = param.Integer(2,bounds=(1,20)) #pour faire varier le nombre de translations que l'on veut faire \n",
    "    Sigma = param.Number(10,bounds=(1,100))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    seuil=param.Integer(10,bounds=(0,500))\n",
    "    def view(self):\n",
    "        np.random.seed(self.seednoise)\n",
    "        I=imagesRef[self.image]\n",
    "        n1,n2=np.shape(I)\n",
    "        B=np.random.randn(n1,n2)\n",
    "        ib=I+self.Sigma*B\n",
    "        ib=np.clip(ib,0,255)\n",
    "        Irec=DebruitTranslation(ib,self.wave,self.seuil,self.NbT)\n",
    "        #on calcule nos PSNRs\n",
    "        PSNR_bruit = PSNR(ib,I)\n",
    "        PSNR_seuil = PSNR(Irec,I)\n",
    "        return pn.Row(hv.Image(ib).opts(title=f'Image bruitée, PSNR={PSNR_bruit:.2f}',cmap='gray'), hv.Image(Irec).opts(title=f'Image reconstruite, PSNR={PSNR_seuil:.2f}', cmap='gray'), hv.Image(I).opts(title=f'Image', cmap='gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavedebruit_trans = Debruit_translat()\n",
    "pn.Row(wavedebruit_trans.param,wavedebruit_trans.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que plus l'on effectue de translations, ainsi plus Nbt est grand, mieux notre image est reconstruite. Cependant, on remarque qu'une faible variation positive du PSNR à partir de Nbt = 10 environ. Sinon on a les mêmes interprétations au niveau du seuil que précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'une image couleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer le débruitage d'une image générale, c'est à dire d'une image couleur dont le format n'est pas carré et dont les dimensions ne sont pas des puissances de 2 on procède comme suit :\n",
    "\n",
    "1) On effectue un débruitage séparé sur chacun des canaux.\n",
    "\n",
    "2) Le format carré n'est pas un vrai problème, il faut juste que les dimensions soient des multiples de puissances de 2. C'est la puissance de 2 qui définira l'échelle maximale de la décomposition en ondelettes. Il est donc préférable que les dimensions de l'images soient un petit multiple d'une puissance de 2.\n",
    "\n",
    "3) On étend l'image par symétrie ou périodicité pour qu'elle ait les dimensions souhaitées. A la fin du processus de débruitage on tronque le résultat obtenu à la dimension de l'image originale.\n",
    "\n",
    "4) Si le niveau de bruit n'est pas connu, il faut l'estimer en utilisant les coefficients d'ondelettes de la plus petite échelle (voir le notebook sur le débruitage de signaux).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposer une fonction qui effectue le débruitage d'une image couleur de dimensions quelconques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction peut prendre en entrée un tableau numpy ou une image dans une format d'images classique.\n",
    "Vous pouvez tester votre programme en bruitant vous même une ou plusieurs images de référence et évaluer le gain en terme de PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1- On débruite pour chaque canaux donc chaque couleur du spectre RGB\n",
    "#Avant on avait une mat 256*256 avec une valeur de nuance de gris\n",
    "#maintenant on a une mat 256*256*3 car il y a des nuances de Red Green Blue\n",
    "def Debruit_Couleur(IB,wave,seuil,NbT):\n",
    "    IB_r, IB_g, IB_b =np.split(IB,3,axis=2) #ici on sépare donc en fonction des coeffs r g et b\n",
    "    #on obtient 3 matrices dont chaque élément est un tableau comportant un élément \n",
    "    #au niveau des dimensions on passe de 256*256*3 <=> 256*256*1\n",
    "    #pour utiliser notre fonction de Débruitage il nous faut recup le coeff de ces tableaux\n",
    "    IB_r=IB_r[:,:,0];IB_g=IB_g[:,:,0];IB_b=IB_b[:,:,0]\n",
    "    \n",
    "    #on applique notre fonction DebruitTranslation pour chaque couleur RGB\n",
    "    Irec_r=DebruitTranslation(IB_r,wave,seuil,NbT)\n",
    "    Irec_g=DebruitTranslation(IB_g,wave,seuil,NbT)\n",
    "    Irec_b=DebruitTranslation(IB_b,wave,seuil,NbT)\n",
    "    Irec = np.stack([Irec_r, Irec_g, Irec_b],axis=2) #on réassemble nos résultats après les avoir calculés séparémment \n",
    "    return Irec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer les méthodes par seuillage dans une base d'ondelettes en effectuant un seuillage par blocs. C'est à dire, ne pas décider de conserver ou pas un coefficients en fonction de sa seule amplitude mais plutôt en fonction de l'énergie d'un voisinage de coefficients. \n",
    "\n",
    "Voir : http://www.cnrs.fr/insmi/spip.php?article265\n",
    "\n",
    "En effet, il est rare qu'un coefficient soit significatif seul au milieu de coefficients nuls. \n",
    "\n",
    "La mméthode de sueillage par blocs consiste à choisir une taille de voisinage (par exemple 4*4 coeffients en dimension 2) pour une échelle et une direction donnée et de conserver l'intégralité des coefficients si l'énergie (la somme des carrés des coefficients) est supérieure à un seuil et de les mettre tous à 0 si ce n'est pas le cas. \n",
    "\n",
    "Dans ce cas aussi, les translations permettent d'améliorer le rendu visuel en limitant les effets de blocs.\n",
    "\n",
    "On peut aussi constuire des blocs \"3D\" en considérant des blocs qui comprennent les coefficients des 3 créneaux de couleurs. L'idée est de corréler le débruitage un peu à travers l'espace et l'espace des couleurs.\n",
    "\n",
    "Il est possible d'effectuer un débruitage en changeant d'espace colorimétrique en passant du RGB au YUV par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Débruiter un minotaure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de tout ce qui a été fait précédemment, proposer une version débruitée de l'image couleur contenue dans le tableau Mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mi=chargeData('Minotaure')\n",
    "Minotaure=np.clip(Mi,0,255)\n",
    "hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rédiger également une fonction prenant en entrée un nom de fichier permettant de calculer le PSNR de votre proposition d'image débruitée avec l'image en question. On calcule le PSNR entre deux images couleurs en calculant la somme des erreurs quadratiques sur les 3 canaux.\n",
    "\n",
    "Attention, l'image a 3 canaux de couleur, n'est pas carrée et les dimensions ne sont pas des puissances de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PSNR_couleur(I,Iref): #on doit donc modifier notre fonction PSNR couleur car on doit calculer le PSNR pour chaque couleur RGB \n",
    "    #Comme précédemment on sépare les couleur : \n",
    "    I_r, I_g, I_b =np.split(I,3,axis=2) ; I_r=I_r[:,:,0] ; I_g=I_g[:,:,0] ; I_b=I_b[:,:,0]\n",
    "    Iref_r, Iref_g, Iref_b =np.split(Iref,3,axis=2) ; Iref_r=Iref_r[:,:,0] ; Iref_g=Iref_g[:,:,0] ; Iref_b=Iref_b[:,:,0]\n",
    "    #Ensuite on reprend notre calcul du PSNR classique\n",
    "    mse_r = np.mean( (Iref_r - I_r) ** 2 )\n",
    "    mse_g = np.mean( (Iref_g - I_g) ** 2 )\n",
    "    mse_b = np.mean( (Iref_b - I_b) ** 2 )\n",
    "    #Puis on somme\n",
    "    mse=mse_r + mse_g + mse_b\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    Val_MAX = np.max(Iref)\n",
    "    return 20 * np.log10(Val_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ca=chargeData('Cartoon')\n",
    "imagesRefCol= {\"Minotaure\" : Mi, \"Cartoon\" : Ca}\n",
    "class Debruit_translat_couleur(param.Parameterized):\n",
    "    #image = param.ObjectSelector(default=\"Minotaure\",objects=imagesRefCol.keys())\n",
    "    image=Minotaure\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    NbT = param.Integer(2,bounds=(1,10)) #on se limite à 10 car précédemment on n'a pas vu d'évolutions pour Nbt > 10\n",
    "    #on n'a plus besoin de bruit car l'image est déjà bruitée d'origine\n",
    "        #Sigma = param.Number(10,bounds=(1,30))\n",
    "        #seednoise = param.Integer(1,bounds=(0,50))\n",
    "    seuil=param.Integer(10,bounds=(0,100))\n",
    "    def view(self):\n",
    "        #on n'a plus besoin de bruit car l'image est déjà bruitée d'origine\n",
    "            #np.random.seed(self.seednoise)\n",
    "            #I=imagesRef[self.image]\n",
    "            #n1,n2=np.shape(I)\n",
    "            #B=np.random.randn(n1,n2)\n",
    "            #ib=I+self.Sigma*B\n",
    "            #ib=np.clip(ib,0,255)\n",
    "        Irec=Debruit_Couleur(self.image,self.wave,self.seuil,self.NbT)\n",
    "        #On calcule le PSNR avec l'IMage Bruitée donc attention l'interprétation change !!\n",
    "        P=PSNR_couleur(self.image,Irec)\n",
    "        \n",
    "        return pn.Row(hv.RGB(self.image.astype('uint8')).opts(title=f'Image bruitée'), \n",
    "                      hv.RGB(Irec.astype('uint8')).opts(title=f'Image reconstruite, PSNR={P:.2f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wavedebruit_trans_couleur = Debruit_translat_couleur()\n",
    "pn.Row(wavedebruit_trans_couleur.param,wavedebruit_trans_couleur.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention ici le PSNR est à interpréter différemment. En effet, on n'a, ici, pas d'image de référence donc on ne peut pas calcule rle PSNR avec cette dernière, donc on le calcule avec l'Image bruitée à droite. Or comme le PSNR nous indique la similarité entre deux images, donc ici il est proche de 0, meilleure est la reconstruction et le débruitage.\n",
    "\n",
    "Ici, nous ne remarquons pas d'influence signifcative de la variable Nbt ainsi le nombre de translations. Cela viendrait probablement du fait que l'image est \"peu\" bruitée, donc avec des petits coefficients de bruitage, ainsi les translations ne sont pas nécessaires et ont peu d'impact sur la qualité de la reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan d'expériences pour évaluer l'impact des translations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'expériences pour explorer les performances de l'invariance par translation pour le débruitage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Bruitage(I,Sigma): #on crée une fonction qui bruite directement nos images avec la même méthode que précédemment\n",
    "    n1,n2=np.shape(I)\n",
    "    B=np.random.randn(n1,n2)\n",
    "    ib=I+Sigma*B\n",
    "    ib=np.clip(ib,0,255)\n",
    "    return ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on fait un plan d'expériences, c'est à dire qu'au lieu d'un dahsboard qui recompile notre fonction à chaque fois, \n",
    "#on la compile directement pour pleins de valeurs différentes pour afficher nos résultats\n",
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences_DebruitTrans = {'Image': imagesRef.keys(),\n",
    "                            'NbT':np.arange(1,10),\n",
    "                            'wave':wavelist,\n",
    "                            'Seuil':np.linspace(50,150,2),\n",
    "                            'Sigma':np.linspace(10,100,10)}\n",
    "dfexp_DebruitTrans=pd.DataFrame(list(itertools.product(*experiences_DebruitTrans.values())),columns=experiences_DebruitTrans.keys()) #on crée donc un dataframe\n",
    "#ce dataframe contient sur chaque ligne tous nos paramètres qu'on utilisera avec notre fonction DebruitTranslation ainsi chaque ligne correspond à une configuration possible.\n",
    "dfexp_DebruitTrans['Result'] = dfexp_DebruitTrans.apply(lambda row : DebruitTranslation(imagesRef[row[\"Image\"]],row[\"wave\"],row[\"Seuil\"],row[\"NbT\"]),axis=1) #on applique notre fonction DebruitTranslation à chaque ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans) #pour afficher notre plan d'exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui calcule le PSNR moyen sur n réalisations de bruit du débruitage d'une image avec NbT*NbT translations (qui utilise par exemple la fonction DebruitTranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debruit_Translat_PSNRMoyen(I,wave,sigma,seuil,NbT,n): #on effectue plusieurs translations et on calcule le psnr moyen\n",
    "    psnr=0\n",
    "    for i in range(n):\n",
    "        ib = Bruitage(I,sigma)\n",
    "        Irec=DebruitTranslation(ib,wave,seuil,NbT)[0]\n",
    "        psnr+=PSNR(I,Irec)/n\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire la fonction qui à une ligne de la base de données précédente calcule le PSNR moyen sur 4 réalisations du bruit. Puis l'appliquer à la base de données et ajouter la colonne des PSNR calculés à la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DebruitTrans(row): #on fait une fonction à qui on donnera une ligne et qui calculera le psnr moyen avec notre fonction ci-dessu.\n",
    "    return Debruit_Translat_PSNRMoyen(imagesRef[row['Image']],\n",
    "                                      row['wave'],\n",
    "                                      row['Sigma'],\n",
    "                                      row['Seuil'],\n",
    "                                      row['NbT']\n",
    "                                      ,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfexp_DebruitTrans['PSNR Moyen'] = dfexp_DebruitTrans.apply(lambda row : row2DebruitTrans(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser les résulatst contenus dans la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#On affiche le graphe du PSNR moyen en fonction des nombres de translation et des différentes bases d'ondelettes, tout en pouvant modifier sigma, donc le bruit, et le seuil.\n",
    "\n",
    "dfexp_DebruitTrans.hvplot('NbT','PSNR Moyen', by='wave',kind='scatter',groupby=['Image','Sigma', 'Seuil']).opts(width=600,tools=[h]).redim.range(PSNR=(0,80),N=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve qu'un petit nombre de translations diminue légèrement le PSNR donc la qualité de reconstruction de l'image, cependant à partir de 4 translations cela commence à remontrer mais cela stagne "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification et Entropie de Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShannonEntropy(x):\n",
    "    value,counts = np.unique(x, return_counts=True)\n",
    "    Proba=counts/len(x)\n",
    "    Ent=-np.sum(np.log2(Proba)*Proba)\n",
    "    return Ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([13,13,2,7,13,7,1,13]) \n",
    "print(ShannonEntropy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([-2,-3,1,0,1,0,-2,-3])\n",
    "print(ShannonEntropy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue la quantification de la transformée en ondelettes avec un pas \"Pas\". On pourra à nouveau utiliser la commande pywt.ravel_coeffs. La fonction doit renvoyer l'image calculée par quantification, le PSNR associé ainsi que le nombre d'octets estimé par la valeur de l'entropie a priori nécessaire pour coder une telle image. On considérera qu'on code séparément les coefficients d'échelle et les coefficients d'ondelettes. Tester la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuantificationOndelettes(I,qmf,Pas):\n",
    "    Lmax = pywt.dwt_max_level(len(I), pywt.Wavelet(qmf).dec_len)\n",
    "    W = pywt.wavedecn(I, qmf, mode='per', level=Lmax)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(W)\n",
    "    arr2=arr.copy()\n",
    "    arr2=np.round(arr2/Pas) * Pas\n",
    "    fac_compression = ShannonEntropy(arr.ravel()) / ShannonEntropy(arr2.ravel()) #calcul du facteur de compression\n",
    "                                                                                       # Donc du nouveau nombre d'octets comparé à l'ancien\n",
    "    coeffs_from_arr = pywt.array_to_coeffs(arr2, coeff_slices)\n",
    "    Irec = pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    P = PSNR(I,Irec)\n",
    "    return Irec, P, fac_compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le dashboard asscoié à la focntion précédente. \n",
    "Le dashboard doit renvoyer l'image quantifiée, le PSNR de l'image ainsi que le facteur de compression théorique associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = im\n",
    "Pas = 30 \n",
    "Irec, psnr, compression = QuantificationOndelettes(I,'haar',Pas)\n",
    "print(\"Facteur de compression :\", compression)\n",
    "hv.Image(Irec).opts(title=f'Image reconstruite, PSNR={psnr:.2f}',cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveQuant(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    QS = param.Number(30,bounds=(10,300))\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    def view(self):\n",
    "        I=imagesRef[self.image]\n",
    "        Irec, psnr, compression = QuantificationOndelettes(I,self.wave,self.QS)\n",
    "                \n",
    "        return pn.Row(hv.Image(I).opts(title=f'Image,PSNR',cmap='gray'),\n",
    "                      hv.Image(Irec).opts(title=f'Image reconstruite, PSNR={psnr:.2f}',cmap='gray'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveQuant=WaveQuant()\n",
    "pn.Row(waveQuant.param,waveQuant.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer dun plan d'expériences pour comparer les différentes ondelettes pour la quantification... et poursuivre jusqu'à obtenir un affichage de la base de données ainsi créée avec hvplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences_WaveQuant = {'Image': imagesRef.keys(),\n",
    "                         'QS':np.linspace(30,200,10),\n",
    "                         'wave':wavelist}\n",
    "\n",
    "dfexp_WaveQuant=pd.DataFrame(list(itertools.product(*experiences_WaveQuant.values())),columns=experiences_WaveQuant.keys())\n",
    "\n",
    "print(dfexp_WaveQuant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR(row):\n",
    "    return row['Result'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def row2DistorsionRate(row):\n",
    "    return row['Result'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_WaveQuant['Result'] = dfexp_WaveQuant.apply(lambda row : QuantificationOndelettes(imagesRef[row[\"Image\"]],row[\"wave\"],row[\"QS\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_WaveQuant['PSNR'] = dfexp_WaveQuant.apply(lambda row : row2PSNR(row), axis = 1)\n",
    "dfexp_WaveQuant['Compression'] = dfexp_WaveQuant.apply(lambda row : row2DistorsionRate(row), axis = 1)\n",
    "\n",
    "\n",
    "print(dfexp_WaveQuant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_WaveQuant.hvplot('Compression','PSNR', by='wave',kind='scatter',groupby=['Image','QS']).opts(width=600,tools=[h]).redim.range(PSNR=(0,110),Compression=(0,120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons ici d'effectuer la compression sur les 3 canau RGB. Or l'oeil humain est plus sensible à la luminance qu'aux composantes purement chromatiques. C'est pourquoi, la plupart des algorithmes de compressions sont effectué dans un espace colorimétrique YUV où Y est la luminance. On alloue alors plus d'information au canal Y et on comprime plus drastiquement les deux autres canaux. Une méthode standart consiste par exemple à sous-échantionner d'un facteur 2 les deux composantes U et V avant de les comprimer. \n",
    "\n",
    "https://fr.wikipedia.org/wiki/Sous-échantillonnage_de_la_chrominance\n",
    "\n",
    "On obtient alors des images de chrominances moins résolues et donc moins lourdes mais le rendu final reste correct car l'oeil humain est nettement plus sensible à la luminance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
