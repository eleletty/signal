{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Backward et FISTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, nous allons utiliser l'algorithme dit Forward Backward et sa version acc√©l√©r√©e appel√©e FISTA pour r√©soudre diff√©rents probl√®mes d'optimisation associ√©s √† de l'inpainting et du d√©bruitage. Nous travaillerons sur les deux images de r√©f√©rence du TP pr√©c√©dent mais √† nouveau, vous pouvez utiliser d'autres images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on installe ceci afin de coder les expressions en latex\n",
    "pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_endpoint_url = 'https://object-rook-ceph.apps.math.cnrs.fr/'\n",
    "s3_access_key_id = '9F7EB8YBUWXDV7A4IZYW' # le contenu de secrets/dossal\n",
    "s3_secret_access_key = 'skV01Eei5M3xVOxROIDr3qymYhWtkrxPpMyj8nwb' # le contenu de secrets/dossal\n",
    "s3_bucket = 'signal-image'\n",
    "s3 = boto3.client('s3',\n",
    "                  '',\n",
    "                  endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)\n",
    "Data=[\"Lenna.jpg\",\"Canaletto.jpeg\",\"MinotaureBruite.jpeg\",\"Cartoon.jpg\"]\n",
    "if not os.path.isfile('Lenna.jpg'):\n",
    "    for filenames in Data:  \n",
    "        s3.download_file(s3_bucket,filenames,filenames)\n",
    "def chargeData(name):\n",
    "    if name=='Lenna':\n",
    "        res=np.array(Image.open(\"Lenna.jpg\")).astype(float)\n",
    "    if name=='Canaletto':\n",
    "        res=np.array(Image.open(\"Canaletto.jpeg\")).astype(float)\n",
    "    if name=='Minotaure':\n",
    "        res=np.array(Image.open(\"MinotaureBruite.jpeg\")).astype(float)  \n",
    "    if name=='Cartoon':\n",
    "        res=np.array(Image.open(\"Cartoon.jpg\")).astype(float) \n",
    "    return res\n",
    "options1=dict(width=400,height=400,xaxis=None,yaxis=None,toolbar=None)\n",
    "options2=dict(width=700,height=400,xaxis=None,yaxis=None,toolbar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im2=chargeData('Lenna')\n",
    "im=chargeData('Canaletto')\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Blocks2,Piece,im,im2,Mi=np.load('dataTP.npy')\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    temp=I.ravel()\n",
    "    tempref=Iref.ravel()\n",
    "    NbP=I.size\n",
    "    EQM=np.sum((temp-tempref)**2)/NbP\n",
    "    b=np.max(np.abs(tempref))**2\n",
    "    return 10*np.log10(b/EQM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le probl√®me d'inpainting on va supposer qu'on dispose d'observations $y=Mx^0+b$ qui sont d√©grad√©es par un op√©rateur de masquage $M$ et √©ventuellement par un bruit additif $b$. On va chercher √† estimer $x^0$ en minimisant une fonctionnelle de la forme \n",
    "\\begin{equation}\\label{Eq1}\n",
    "\\frac{1}{2}\\Vert Mx-y\\Vert^2+\\lambda \\Vert Tx\\Vert_1\n",
    "\\end{equation}\n",
    "o√π $T$ est une transform√©e dans laquelle on sait que l'image $x^0$ est parcimonieuse (typiquement une bonne base d'ondelettes comme db2). Pour utiliser le FB, il faut calculer le gradient du terme d'attache aux donn√©es et l'op√©rateur proximal de $\\Vert Tx\\Vert_1$. Vous aurez de l'aide plus loin dans le notebook pour cette partie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le bruit est nul, c'est-√†-dire si $y=Mx^0$, o√π $M$ est un op√©rateur de masquage, il serait m√™me plus int√©ressant de d√©terminer une solution du probl√®me d'optimisation suivant :\n",
    "\\begin{equation}\\label{Eq2}\n",
    "\\underset{x}{\\min}\\Vert Tx\\Vert_1\\text{ sous la contrainte }y=Mx  \n",
    "\\end{equation}\n",
    "Ce probl√®me d'optimisation ne peut √™tre r√©solu directement par par l'algorithme Forward-Backward (FB) car on ne peut pas le formuler comme une minimsaition d'une somme de deux fonctions dont l'onde est diff√©rentiable √† gradient Lipschitz. \n",
    "De plus, en pratique, il est souvent illusoire de penser que les donn√©es $y$ ne sont pas corrompues par un bruit, aussi petit soit il. \n",
    "\n",
    "On peut d√©montrer que les solutions de \\eqref{Eq1} convergent ver une solution de \\eqref{Eq2} quand $\\lambda$ tend vers 0. L'avantage de cette formulation \\eqref{Eq1} est qu'elle peut √™tre r√©solu par FB. \n",
    "R√©soudre \\eqref{Eq1} revient ainsi √† la fois √† inpainter et √† r√©gulariser. Plus $\\lambda$ est grand plus on r√©gularise. Dans la pratique, en l'absence de bruit, on a int√©r√™t √† choisir une petite valeur de $\\lambda$ dans la formulation \\eqref{Eq1}. Le probl√®me dun tel choix est que √ßa ralentit l'algorithme : i.e il faut un plus grand nombre d'it√©rations pour atteindre un r√©sultat comparable si on prend le m√™me point de d√©part. Quand on utilise ces m√©thodes, les choix de $\\lambda$, du nombre d'it√©rations et du point de d√©part de l'algorithme sont importants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rappels sur la descente de gradient explicite et sur Forward-Backward (FB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $F=f+g$ est une fonction convexe composite, somme de deux fonctions convexes, $f$ diff√©rentiable √† gradient \n",
    "$L$-Lipschitz et $g$ une fonction convexe dont on sait calculer l'op√©rateur proximal, l'algorithme Forward-Backward s'√©crit \n",
    "$$x_{n+1}=prox_{hg}(x_n-h\\nabla f(x_n))=Tx_n\\quad \\text{ avec }T:=prox_{hg}\\circ (Id-h\\nabla f)$$\n",
    "\n",
    "On peut montrer que la suite de terme g√©n√©ral $F(x_n)-F(x^*)$ est d√©croissante et de plus que \n",
    "$$F(x_n)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{hn}$$\n",
    "Cette vitesse en $\\frac{1}{n}$ est optimale au sens o√π il n'est pas possible de trouver des bornes qui d√©croissent en $\\frac{1}{n^{\\delta}}$ avec $\\delta>1$ pour toutes les fonctions convexes. Cela √©tant on peut montrer que si $h<\\frac{1}{L}$ on a en fait \n",
    "$$F(x_n)-F(x^*)=o\\left(\\frac{1}{n}\\right)$$\n",
    "et que cette vitesse est m√™me g√©om√©trique si la fonction $f$ est fortement convexe, dans le cas diff√©rentiable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarques sur les algorithmes it√©ratifs en g√©n√©ral et FB en particulier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on utilise un algorithme it√©ratif qui d√©pend d'un ou plusieurs param√®tres, il faut √™tre vigilent pour √©valuer ses performances. Il est important de s'assurer d'une mani√®re ou d'une autre des points suivants :\n",
    "\n",
    "1) V√©rifier qu'on est proche de la convergence... c'est-√†-dire qu'on a fait suffisamment d'it√©rations. Ce nombre peut varier en fonction des param√®tres de l'agorithme et du point initial $x_0$ choisi pour construire la suite.\n",
    "\n",
    "Je vous invite pour cela √† afficher la courbe de la valeur de la fonctionnelle et √† prendre un peu de recul sur ce que vous observez. S'il reste des pixels noirs qui sont manifestement des r√©sidus du masque ou si la fonctionnelle d√©croit encore fortement, c'est qu'il faut sans doute augmenter le nombre d'it√©rations. D'une mani√®re g√©n√©rale, observer les artefacts (d√©fauts) de l'image reconstruite peut donner des √©l√©ments de r√©ponses.\n",
    "De plus, observer la courbe de la valeur de la fonctionnelle peut parfois indiquer qu'on aurait pu effectuer moins d'it√©rations pour un r√©sulat comparable. \n",
    "\n",
    "2) Explorer les valeurs des param√®tres. Il se peut que certaines valeurs de param√®tres fournissent des r√©sultats pertinents, d'autres non. Avant de trancher sur le caract√®re efficace d'une m√©thode, il faut avoir pris le temps de v√©rifier que le choix des param√®tres est correct. Les param√®tres peuvent √™tre ceux de la fonctionnelle √† minimiser, comme le $\\lambda$ de \\eqref{Eq1} mais aussi des param√®tres internes √† l'algorithme comme le pas de descente par exemple. Le fait de faire un plan d'exp√©riences dans ce cas sur des donn√©es tests peut √™tre un bon moyen de d√©terminer des param√®tres pertinents. \n",
    "\n",
    "On peut noter que la valeur de la fonctionnelle ne fait pas tout, en effet si on veut comparer diff√©rentes valeur de $\\lambda$, c'est plut√¥t le PSNR de la reconstruction qui sera un crit√®re pertinent. On ne peut pas se passer de r√©fl√©chir... \n",
    "\n",
    "3) Bien choisir la valeur initiale de la suite. Les algorithmes it√©ratifs construisent de mani√®re s√©quentielle des images qui s'approchent du minimiseur de la fonctionnelle. Le choix du point de d√©part de la suite peut √™tre crucial.\n",
    "Si on ne dispose d'aucune information a priori, on peut partir d'une image constante √† 0 ou d'une image raisonnable.\n",
    "Par exemple, de l'image masqu√©e si on fait de l'inpainting, ou de l'image bruit√©e si on fait du d√©bruitage.\n",
    "\n",
    "On peut souvent distinguer deux phases dans l'optimisation de la fonctionnelle, une premi√®re qui permet de passer de l'image initiale vers une image raisonnable, une approximation grossi√®re du r√©sultat, puis une seconde qui permet de passer de cette premi√®re approximation grossi√®re √† une image tr√®s proche du r√©sultat final souhait√©.\n",
    "Il est difficile d'esquiver la seconde phase mais on peut r√©duire drastiquement la premi√®re en proposant une image initiale d√©j√† tr√®s raisonnable. On peut par exemple lancer un algorithme classique rapide, mais pas tr√®s pr√©cis pour donner une image initiale meilleure qu'une initialisation al√©atoire ou na√Øve. \n",
    "Dans le cas du d√©bruitage, on peut par exemple filtrer l'image originale ou la seuiller en ondelettes. Dans le cas de l'inpainting on peut appliquer localement un filtre m√©dian. C'est-√†-dire on d√©coupe l'image en blocs de taille fixe (8 par 8 par exemple) et sur chaque bloc on estime la valeur m√©dianne d'intensit√© lumineuse parmi les valeurs non masqu√©es et on remplace, sur chaque bloc, les valeurs inconnues par cette valeur. C'est primitif mais rapide et √ßa permet d'avoir une premi√®re estimation raisonnable.\n",
    "\n",
    "D'une mani√®re g√©n√©rale, si vous voulez comparer plusieurs m√©thodes, avec des param√®tres ou des bases d'ondelettes diff√©rentes, il est pertinent de calculer le PSNR des images reconstruites. \n",
    "C'est une mani√®re d'obtenir un crit√®re un minimum objectif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©but de notre TP :\n",
    "\n",
    "Avant de nous lancer dans les algorithmes d'optimisation, commen√ßons par expliciter les calculs de gradient et de l'op√©rateur proximale dont nous allons nous servir pour la suite. Notre objectif est de minimiser :\n",
    "\n",
    "$$\n",
    "\\hat{x} = argmin_{x \\in \\mathbb{R}^n } \\frac{1}{2} {\\lVert Mx - y \\rVert}¬≤_{2} + \\lambda {\\lVert Tx \\rVert}_{1} := F(x)\n",
    "$$\n",
    "\n",
    "On note :\n",
    "$$ f(x) =\\frac{1}{2} {\\lVert Mx - y \\rVert}¬≤_{2}$$ \n",
    "\n",
    "et \n",
    "\n",
    "$$ g(x) =\\lambda {\\lVert Tx \\rVert}_{1}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x)$ √©tant une fonction diff√©renciable, on peut calculer son gradient tel que :\n",
    "    $$\\nabla f(x) = M^T(Mx-y) = M(Mx-y)$$\n",
    "    \n",
    "$g(x)$ n'√©tant que convexe on calcule son op√©rateur proximal tel que : \n",
    "$$ prox_{h¬∞g}(x) = T*soft_h(Tx) $$ o√π $soft$ repr√©sente le seuillage doux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, pour que FB soit un algorithme de descente, il nous faut $h< \\frac{1}{L}$, o√π $h$ correspond au pas et $L$ √† la constante de Lipschitz de la fonction $f$. Or $L=1$ ici car :\n",
    "$${\\lVert M \\rVert}= 1$$d'o√π $${\\lVert M \\rVert}¬≤= 1$$\n",
    "\n",
    "Ainsi notre condition sur $h$ est : $h<1$ pour que l'algorithme soit un algorithme de descente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place de FB pour l'inpainting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourra commencer dans un premier temps par des observations non bruit√©es et effectuer seulement un masquage. Pour cr√©er un masque 2D, on peut utiliser les lignes de commandes suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)\n",
    "n1,n2=np.shape(im)\n",
    "r=np.random.rand(n1,n2) #pour cr√©er le masquage\n",
    "M=(r<0.5)\n",
    "M = M*1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut bien entendu faire varier la proportion de l'image qu'on masque.\n",
    "\n",
    "On masque l'image de la mani√®re suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp=M*im\n",
    "pn.Row(hv.Image(im).opts(cmap='gray',width=400,height=400),hv.Image(temp).opts(cmap='gray',width=400,height=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilisation par un filtre m√©dian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer et tester un algorithme de Filtre m√©dian qui r√©alise un inpainting primaire en rempal√ßant les pixels manquants par la mediane des coefficients observ√©s sur des carr√©s de taille vois*vois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FiltreMedian(im,masque,vois):\n",
    "    imrec=np.copy(im)\n",
    "    n1,n2=np.shape(im)\n",
    "    K1=int(np.floor(n1/vois))\n",
    "    K2=int(np.floor(n2/vois))\n",
    "    #print(np.arange(K1))\n",
    "    #print(np.arange(vois))\n",
    "    for k1 in np.arange(K1): #Boucle sur le nombre de carr√©\n",
    "        k1=8*k1 #on fait fois 8 pour ne pas reboucler sur un carr√© d√©j√† compl√©t√©\n",
    "        for k2 in np.arange(K2):\n",
    "            k2=8*k2 #idem pour ne pas reboucler sur un carr√© d√©j√† complet√©\n",
    "            median=[] #pour calculer la m√©diane dans un carr√©\n",
    "            for kk1 in np.arange(vois): #Boucle pour calculer la m√©diane sur le carr√© de taille VOISxVOIS\n",
    "                for kk2 in np.arange(vois):\n",
    "                    if imrec[k1+kk1,k2+kk2] != 0: #si jamais le pixel n'est pas masqu√© on append sa valeur dans le calcul de la m√©diane \n",
    "                        median.append(imrec[k1+kk1,k2+kk2])\n",
    "            med = np.median(median) #calcul de la m√©diane\n",
    "            #print(med)\n",
    "            for kk1 in np.arange(vois): #Boucle pour remplacer la m√©diane calcul√©e ci-dessus sur les pixels √† valeurs nuls \n",
    "                for kk2 in np.arange(vois):\n",
    "                    if imrec[k1+kk1,k2+kk2] == 0:\n",
    "                        imrec[k1+kk1,k2+kk2]=med\n",
    "        \n",
    "    return(imrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imrec2=FiltreMedian(temp,M,8) #on prend vois=8 pour la taille des carr√©s\n",
    "hv.Raster(temp).opts(cmap='gray',xaxis=None,yaxis=None,width=350,height=350)\\\n",
    "+hv.Raster(imrec2).opts(cmap='gray',xaxis=None,yaxis=None,width=350,height=350) \n",
    "#on affiche les deux images masqu√©e et reconstruite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retour sur l'algorithme FB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer une fonction qui calcule le gradient de la fonction $f(x)=\\frac{1}{2}\\Vert Mx-y\\Vert^2$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GradientInpainting(x,y,M): #pour calculer le gradient de f(x)\n",
    "    return M*(M*x - y) #normalement on devrait avoir Mtranspose mais ici M est sym√©trique donc on peut laisser M tout court !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour quelle valeur $L$ ce gradient est-il $L$-Lipschitz ? \n",
    "\n",
    "**Pour L=1 le grandient est Lipshcitz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions suivantes permettent d'√©valuer l'op√©rateur proximal de la fonction \n",
    "$g(x)=\\lambda \\Vert Tx\\Vert_1$ o√π $T$ est une transform√©e orthogonale en ondelettes ou une transform√©e en ondelettes √† trou, c'est-√†-dire invariante par translation. Vous noterez qu'une transform√©e en Ondelettes de Daubechies db2 √† √©t√© choisie ici par d√©faut mais que ce ci peut bien entendu √™tre chang√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SeuillageDouxOndelettes(I,wave,Seuil): #Un seuillage doux √©quivaut ici au calcul de l'op√©rateur proximal de la fonction g(x), on r√©utilise la m√™me fonction que dans le TP Debruitage Ondelettes 2D\n",
    "    L=pywt.dwt_max_level(len(I),pywt.Wavelet(wave).dec_len)\n",
    "    wavelet_coeffs= pywt.wavedecn(I, wave, mode='per', level=L)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(wavelet_coeffs)\n",
    "    temp=pywt.threshold(arr,Seuil,mode='soft')\n",
    "    test=pywt.unravel_coeffs(temp, coeff_slices, coeff_shapes, output_format='wavedecn')\n",
    "    Irec=pywt.waverecn(test, wave,mode='per')\n",
    "    return Irec\n",
    "def Normel1Ondelettes(I,wave): #fonction qui calcule la norme 1 de Tx donc nous donne une valeur explicite de la fonction g(x)\n",
    "    L=pywt.dwt_max_level(len(I),pywt.Wavelet(wave).dec_len)\n",
    "    wavelet_coeffs= pywt.wavedecn(I, wave, mode='per', level=L)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(wavelet_coeffs)\n",
    "    norml1=sum(np.abs(arr))\n",
    "    return norml1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wave='haar'\n",
    "imrec=SeuillageDouxOndelettes(im,wave,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer et tester un code d'inpaiting utilisant Forward-Backward minimisant la fonctionnelle (1) et la tester.\n",
    "\n",
    "On pensera √† cliper le r√©sultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ForwardBackwardInpaintingv2(y,M,step,lam,Niter,wave):\n",
    "    #z=y\n",
    "    z=np.zeros(y.shape)\n",
    "    F=[]\n",
    "    for i in range(Niter): #on boucle sur un nombre d'it√©rations arbitraire pour minimiser la fonction (il faut juster garder le m√™me en FB qu'en FISTA pour que √ßa soit comprabale)\n",
    "        z = SeuillageDouxOndelettes(z-step*GradientInpainting(z,y,M),wave,lam) #lambda repr√©sente ici le seuil\n",
    "        F.append(1/2 * np.linalg.norm(M*z-y,2)**2 + lam * Normel1Ondelettes(z,wave)) #on append la valeur de la fonction minimis√©e apr√®s une it√©ration de l'algo de FB\n",
    "    return np.clip(z,0,255),F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y=M*im\n",
    "step=3\n",
    "#step=20\n",
    "lam=10\n",
    "Nb_iter=100\n",
    "wave='haar'\n",
    "Ta=350\n",
    "imrec,f=ForwardBackwardInpaintingv2(y,M,step,lam,Nb_iter,wave)\n",
    "pn.Row(hv.Image(im).opts(cmap='gray',width=Ta,height=Ta),\\\n",
    "       hv.Image(y).opts(cmap='gray',width=Ta,height=Ta)\\\n",
    "       ,hv.Image(imrec).opts(cmap='gray',width=Ta,height=Ta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f).opts(xlabel='Nombre d\\'it√©rations', ylabel='F(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "On voit que si le 'step' est tr√®s grand (ex : 20) notre fonction co√ªt explose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer un dashboard permettant une exploration num√©rique de la fonction pr√©c√©dente. On pourra ainsi observer que les petites valeurs de $\\lambda$ donnent de meilleurs r√©sulats. En th√©orie, si les donn√©es observ√©es ne sont pas bruit√©es, il faudrait prendre une valeur de $\\lambda$ aussi petite que possible. Vous pouvez le remarquer si vous affichez le PSNR de l'image reconstruite et que vous faites un nombre suffisant d'it√©rations.\n",
    "\n",
    "Le probl√®me d'un tel choix est que cela ralentit consid√©rablement l'algorithme. Si les donn√©es sont bruit√©es, la valeur optimale de $\\lambda$ est proportionnelle √† l√©cart type du bruit.  \n",
    "\n",
    "Ainsi, vous aurez int√©r√™t √† choisir une valeur faible de $\\lambda$ mais pas trop petite pour assurer que votre algorithme est proche de la convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBInpaint(param.Parameterized): #on cr√©e une classe FB Inpaint pour mieux visualiser les r√©sultats de notre algorithme en modifiant les param√®tres\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    Niter = param.Integer(30,bounds=(0,100))\n",
    "    lam = param.Number(10,bounds=(1,30))\n",
    "    step = param.Number(0.9,bounds=(0.5,4))\n",
    "    masquage = param.Number(0.5,bounds=(0.1,1))\n",
    "    def view(self):\n",
    "        I=imagesRef[self.image]\n",
    "        M = np.random.rand(*I.shape) #on cr√©e un masque\n",
    "        M[M<self.masquage] = 0\n",
    "          \n",
    "        imasqu=M*I #on recr√©e l'image masqu√©e\n",
    "        \n",
    "        \n",
    "        Irec,F=ForwardBackwardInpaintingv2(imasqu, M, self.step,self.lam,self.Niter,self.wave) \n",
    "        \n",
    "        #Calcul des PSNRs des images masqu√©es et reconstruites par rapport √† l'image classique\n",
    "        PSNR_masq = PSNR(I,imasqu)\n",
    "        PSNR_rec = PSNR(I,Irec)\n",
    "        \n",
    "        return pn.Row(hv.Image(I).opts(title=f'Image classique',cmap='gray'), \n",
    "                      hv.Image(imasqu).opts(title=f'Image masqu√©e, PSNR={PSNR_masq:.2f}', cmap='gray'), \n",
    "                      hv.Image(Irec).opts(title=f'Image reconstruite, PSNR={PSNR_rec:.2f}', cmap='gray'))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbinpaint= FBInpaint()\n",
    "pn.Row(fbinpaint.param,fbinpaint.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dashboard permet de faire varier les diff√©rents param√®tres de notre algorithme, en particulier le pas que l'on a d√©fini en tant que $h$ dans notre mod√®le. On voit notamment qu'en prenant un $h$ plus grand que 1 notre image est, comme pr√©vu, gris√©e car on ne la d√©masque pas (cela est d√ª √†l'explosion de la fonction co√ªt). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que si step > 1 alors on a le PSNR qui explose vers +inf et on a plus d'image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acc√©l√©ration de Nesterov, FISTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yuri Nesterov a propos√© dans les ann√©es 1980 plusieurs m√©thodes permettant l'acc√©l√©ration de la descente de gradient explicite. Nous allons nous int√©resser √† une en particulier, celle qui est d√©taill√©e dans le polycopi√© de cours. Si vous faites des recherches bibliographiques, soyez conscients que sous le terme \"Acc√©l√©ration de Nesterov\" peuvent se cacher diff√©rentes m√©thodes, par interpolation ou extrapolation, sp√©cifiques aux fonctions fortement convexes ou pas, s'appliquant √† une descente de gradient simple ou √† des fonctions composites. De plus nous n'utiliserons pas les param√®tres historiques propos√©s par Nesterov, mais ceux qu'Antonin Chambolle et moi m√™me avons propos√© en 2014 pour en am√©liorer la vitesse et la convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=np.array([-2,-3,1,0,1,0,-2,-3])\n",
    "print(ShannonEntropy(y))\n",
    "L'acc√©l√©ration de la descente de gradient propos√©e Yurii Nesterov en 1984 et adapat√©e √† FB sous le nom de FISTA par Beck et Teboulle en 2009 est d'une mise en oeuvre tr√®s simple.\n",
    "\n",
    "Il suffit d'effectuer la descente de gradient en un point d√©cal√© de $x_n$ avec un pas $h<\\frac{1}{L}$ (attention cette borne est plus contraignante que pour la descente de gradient classique) :\n",
    "$$x_{n+1}=T(x_n+\\alpha_n(x_n-x_{n-1}))$$ \n",
    "o√π la suite $\\alpha_n$ est bien choisie et $T$ st soit l'op√©rateur de descente de gradient explicite, soit l'op√©rateur associ√© au FB. On parle de m√©thode inertielle car cette m√©thode utilise un terme dit de \"m√©moire\" ou inertiel qui exploite la derni√®re direction de descente.\n",
    "\n",
    "Donnons quelques √©l√©ments cl√©s importants :\n",
    "\n",
    "1) Le choix original de Nesterov pour la suite $\\alpha_n$ ets le suivant :\n",
    "\\begin{equation}\n",
    "\\alpha_n=\\frac{t_n-1}{t_{n+1}}\\text{ avec }t_1=1\\text{ et }t_{n+1}=\\frac{1+\\sqrt{1+t_n^2}}{2}\n",
    "\\end{equation}\n",
    "2) Pour ce choix on a \n",
    "$$F(x_n)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{hn^2}$$\n",
    "3) On peut prendre plus simplement $\\alpha_n=\\frac{n-1}{n+a-1}$ avec $a>3$ (c'est ce que vous programmerez) dans ce cas, on a $$F(x_n)-F(x^*)\\leqslant \\frac{(a-1)^2\\Vert x_0-x^*\\Vert^2}{2h(n+a)^2}$$ et en plus $F(x_n)-F(x^*)=o\\left(\\frac{1}{n^2}\\right)$ et on a convergence de la suite $(x_n)_{n\\geqslant 1}$. On peut noter que dans ce cas, la premi√®re √©tape est une simple sans inertie ($\\alpha_1=0$) et donc $x_1=T(x_0)$. L'inertie apparait pour le calcul de $x_2$. Le choix originel de Nesterov est tr√®s proche du choix $a=3$. \n",
    "\n",
    "4) Dans le cas d'un fonction composite, on parle de l'algotithme FISTA (Fast Iterative Soft Shrinckage Algorithm) car si $g$ est une norme $\\ell_1$, l'op√©rateur proximal se r√©duit √† un seuillage doux. Mais FISTA est le nom g√©n√©rique propos√© par Beck et Teboulle en 2009, ce peut √™tre trompeur.\n",
    "\n",
    "5) La suite de terme g√©n√©ral $F(x_n)-F(x^*)$ n'est pas n√©cessairemment d√©croissante comme dans le cas de FB ou de la descente de gradient. Les bornes donn√©es pr√©c√©demment sont des bornes mais ne refl√®tent pas la d√©croissance r√©elle. Dans la pratique vous verrez que FISTA est quand m√™me plus rapide que FB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer un algorithme d'inpainting consistant √† minimiser la fonctionnelle (1) en utilisant FISTA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTAInpainting(y,M,step,lam,Niter,wave,alpha):\n",
    "    z=np.zeros(y.shape)\n",
    "    z_old=z\n",
    "    F=[] #F=[1/2 * np.linalg.norm(M*z-y,2)**2 + lam * Normel1Ondelettes(z,wave)]\n",
    "    for k in np.arange(0,Niter):\n",
    "        #on garde la formule 3 car on a bien a>4 car elle est plus simple \n",
    "        temp=z+(k/(k+alpha))*(z-z_old) #ici alpha = a initial donc 4 tous le temps\n",
    "        z_old=z\n",
    "        z= SeuillageDouxOndelettes(temp-step*GradientInpainting(temp,y,M),wave,lam) #on applique la fonction seuillage doux en appliquant bien la fonction qui calcule le gradient de la norme \n",
    "        F.append(1/2 * np.linalg.norm(M*z-y,2)**2 + lam * Normel1Ondelettes(z,wave))\n",
    "    return np.clip(z,0,255),F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imrec,fista=FISTAInpainting(y,M,step,lam,Nb_iter,wave,4) \n",
    "#on garde le m√™me lambda pour que l'on minimise bien la m√™me fonction qu'en FB pour qu'on puisse comparer\n",
    "#De m√™me on garde le m√™me NB_iter dans les deux fonctions √©galement !\n",
    "pn.Row(hv.Image(im).opts(cmap='gray',width=Ta,height=Ta),\\\n",
    "       hv.Image(y).opts(cmap='gray',width=Ta,height=Ta)\\\n",
    "       ,hv.Image(imrec).opts(cmap='gray',width=Ta,height=Ta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On cr√©e de nouveau une classe pour l'affichage\n",
    "class FISTAInpaint(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    Niter = param.Integer(10,bounds=(0,300))\n",
    "    lam = param.Number(10,bounds=(1,30))\n",
    "    step = param.Number(0.9,bounds=(0.5,4))\n",
    "    masquage = param.Number(0.5,bounds=(0.1,1)) #: pas utile dans notre fonction\n",
    "    alpha = param.Number(3,bounds=(1,10))\n",
    "    def view(self):\n",
    "        I=imagesRef[self.image]\n",
    "        imasqu=M*I #on recr√©e l'image masqu√©e\n",
    "        \n",
    "        Irec2,F2=FISTAInpainting(I,self.masquage,self.step,self.lam,self.Niter,self.wave,self.alpha)\n",
    "        \n",
    "        #Calcul des PSNRs des images masqu√©es et reconstruites par rapport √† l'image classique\n",
    "        PSNR_masq = PSNR(I,imasqu)\n",
    "        PSNR_rec = PSNR(I,Irec2)\n",
    "        \n",
    "        return pn.Row(hv.Image(I).opts(title=f'Image classique',cmap='gray'), \n",
    "                      hv.Image(imasqu).opts(title=f'Image masqu√©e, PSNR={PSNR_masq:.2f}', cmap='gray'), \n",
    "                      hv.Image(Irec2).opts(title=f'Image reconstruite, PSNR={PSNR_rec:.2f}', cmap='gray'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fistainpaint= FISTAInpaint()\n",
    "pn.Row(fistainpaint.param,fistainpaint.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Curve(fista).opts(xlabel='Nombre d\\'it√©rations', ylabel='F(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On veut d√©sormais v√©rifier que l'algo FISTA est bien + rapide que l'algo FB, du coup on affiche les deux courbes sur le m√™me graphique :** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "curve1 = hv.Curve(f, label='FB')\n",
    "curve2 = hv.Curve(fista, label='FISTA')\n",
    "\n",
    "curves = curve1 * curve2 #pour afficher les deux courbes sur le m√™me plot\n",
    "\n",
    "curves.opts(legend_position='right', width=600, height=400,xlabel='Nombre d\\'it√©rations', ylabel='F(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit bien que l'algo FISTA minimise la fonction plus rapidement : une 15aine d'it√©rations contre plus de 40 pour FB.\n",
    "\n",
    "On remarque une petite vaguelette sur la courbe FISTA car contrairement au FB ce n'est pas un algo de descente uniforme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pour aller plus loin (facultatif et √† titre d'information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour le d√©bruitage, on peut utiliser des bases d'ondelettes translat√©es pour am√©liorer la qualit√© de l'inpainting. Dans ce cas, il ne faut √©videmment pas recalculer l'inpainting depuis le d√©but pour chaque version translat√©e, mais utiliser comme initialisation les versions inpaint√©es pr√©c√©dentes. \n",
    "Cette variante permet √©galement de lisser les d√©fauts et supprime des effets li√©s √† la forme de l'ondelettes et donc les effets de blocs si on utilise les ondelettes de Haar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©bruitage par minimisation de la variation totale (Facultatif d'apr√®s Monsieur Nguyen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'image qu'on souhaite d√©bruiter une image dont on sait qu'elle a une faible variation totale (norme $\\ell_1$ du gradient), on peut estimer l'image en minimisant une fonctionnelle . Attention, on parle ici du gradient de l'image, pas d'une fonctionnelle qui associe une image √† un r√©el. \n",
    "Le gradient d'une image est un champ de vecteur avec deux composantes, l'une verticale, l'autre horizontal qui se calcule de mani√®re classique par diff√©rence finie. J'ai fait le choix dans les codes propos√©s d'une discr√©tisation du gradient et de la discr√©tisation de l'op√©rateur adjoint associ√©. En particulier, cette version n'est pas p√©riodis√©e. Si vous voulez utiliser une autre impl√©mentation du gradient discret, il est probable qu'il faille recoder l'op√©rateur \n",
    "adjoint.\n",
    "\n",
    "Si on note $y=x^0+b$ les observations o√π $x^0$ est l'image √† estimer et $b$ un bruit additif, cette fonctionnelle sera de la forme \n",
    "\\begin{equation}\\label{Primal}\\tag{Primal}\n",
    "\\frac{1}{2}\\Vert x-y\\Vert^2+\\lambda \\Vert \\nabla x\\Vert_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12‚Äñùë•‚àíùë¶‚Äñ2+ùúÜ‚Äñ‚àáùë•‚Äñ1(Primal)Minimiser une telle fonctionnelle revient √† caluler l'op√©rateur proximal de la fonction \n",
    "$g(x)=\\lambda \\Vert \\nabla x\\Vert_1$, or il n'existe pas de formule pour un tel op√©rateur. Ce qui implique aussi que r√©aliser un Forward Backward avec le terme quadratique comme terme diff√©rentiable ne peut pas fonctionner, il n√©cessite la connaissance de cet op√©rateur proximal.\n",
    "\n",
    "Il existe cependant un moyen d'utiliser l'algorithme FB pour r√©soudre ce probl√®me : on proc√®de par dualisation.\n",
    "Il n'est pas possible de d√©tailler cette approche ici, je vous renvoie sur le Poly. La dualisation qui utilise la conjugu√© de Fenchel Rockafellar permet de montrer qu'on peut associer au probl√®me pr√©c√©dent, le probl√®me doptimisation suivant\n",
    "\\begin{equation}\\label{Dual}\\tag{Dual}\n",
    "\\min_{p}\\frac{1}{2}\\Vert div(p)+y\\Vert^2+\\iota_{\\mathcal{B}_{\\infty,\\lambda}}(p)\n",
    "\\end{equation}\n",
    "o√π $p$ est un champ de gradient et \n",
    "o√π $\\iota_{\\mathcal{B}_{\\infty,\\lambda}}$ est la boule $\\ell_{\\infty}$ de rayon $\\lambda$ et o√π $div$ est l'op√©rateur \n",
    "de divergence. La pr√©sence de la divergence est ici due au fait que $-div$ est l'op√©rateur adjoint du gradient $\\nabla$. La norme $\\infty$ est ici pr√©sente car c'est la norme duale de la norme $/ell_1$.\n",
    "\n",
    "Si $p^*$ est la solution du probl√®me pr√©c√©dent alors $x^*=y+div(p^*)$ est la solution du probl√®me initial.\n",
    "\n",
    "L'avantage de ce second probl√®me est qu'il peut √™tre r√©solu par l'algorithme FB dans la mesure o√π le terme non diff√©rentiable est une indicatrice d'un ensemble sur lequel on sait projeter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions suivantes permettent de calculer le gradient et la divergence.\n",
    "Tel que tout est cod√© ici, il s'agit d'une divergence n√©gative, c'est √† dire l'oppos√© de la divergence. A vous de voir si vous voulez tout remodifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientHor(x):\n",
    "    y=x-np.roll(x,1,axis=1)\n",
    "    y[:,0]=0\n",
    "    return y\n",
    "def GradientVer(x):\n",
    "    y=x-np.roll(x,1,axis=0)\n",
    "    y[0,:]=0\n",
    "    return y\n",
    "def DivHor(x):\n",
    "    N=len(x[0])\n",
    "    y=x-np.roll(x,-1,axis=1)\n",
    "    y[:,0]=-x[:,1]\n",
    "    y[:,N-1]=x[:,N-1]\n",
    "    return y\n",
    "def DivVer(x):\n",
    "    N=len(x)\n",
    "    y=x-np.roll(x,-1,axis=0)\n",
    "    y[0,:]=-x[1,:]\n",
    "    y[N-1,:]=x[N-1,:]\n",
    "    return y\n",
    "def Gradient(x):\n",
    "    y=[]\n",
    "    y.append(GradientHor(x))\n",
    "    y.append(GradientVer(x))\n",
    "    return y\n",
    "def Div(y):\n",
    "    x=DivHor(y[0])+DivVer(y[1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjGradBouleInf(g,l):\n",
    "    gh=g[0]\n",
    "    gv=g[1]\n",
    "    temp=g\n",
    "    p0=gh-(gh-l)*(gh>l)-(gh+l)*(gh<-l)\n",
    "    p1=gv-(gv-l)*(gv>l)-(gv+l)*(gv<-l)\n",
    "    temp[0]=p0\n",
    "    temp[1]=p1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer une fonction Python qui r√©sout le probl√®me dual par Forward Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBDenoisingTV(y,l,step,Niter):\n",
    "    #ForwardBackwardInpaintingv2(y,M,step,lam,Niter,wave)\n",
    "    return np.clip(x,0,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester ce code sur un exemple d'image bruit√©e par un bruit gaussien. L'image r√©sultante subit un effet Cartoon. Pourquoi ? Faite varier les param√®tres pour voir les effets des diff√©rents param√®tres de l'algorithme.  \n",
    "Le pas doit √™tre maintenu en dessous de $1/8$ pour v√©rifier les conditions de Lipschitz du gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1,n2=np.shape(im2)\n",
    "Sigma=30\n",
    "Noise=np.random.randn(n1,n2)\n",
    "imb2=im2+Sigma*Noise\n",
    "imrec2=FBDenoisingTV(imb2,25,0.1,2000)\n",
    "pn.Row(hv.Image(im2).opts(cmap='gray',width=Ta,height=Ta),\\\n",
    "       hv.Image(np.clip(imb2,0,255)).opts(cmap='gray',width=Ta,height=Ta)\\\n",
    "       ,hv.Image(imrec2).opts(cmap='gray',width=Ta,height=Ta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cr√©er le dashboard associ√© et tester l'algorithme sur diff√©rentes images et faites varier les param√®tres.\n",
    "Le dashboard doit renvoyer 3 images et 2 PSNR. Vous devrier observer un effet \"cartoon\" surtout pour de grandes valeurs du param√®tre $\\lambda$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingTVFB(param.Parameterized):\n",
    "    Niter = param.Integer(100,bounds=(0,500))\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    lam = param.Number(9,bounds=(1,50))\n",
    "    step = param.Number(0.1,bounds=(0.1,2))\n",
    "    Sigma = param.Number(17,bounds=(1,100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoisingTVFB=DenoisingTVFB()\n",
    "pn.Row(denoisingTVFB.param,denoisingTVFB.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que donnerait cette approche sur des images type \"Cartoon\" ? Tester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A faire ensuite..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Si ce n'est d√©j√† fait, on peut acc√©l√©rer le code en initialisant la suite par un seuillage simple en ondelettes...\n",
    "On peut m√™me essayer de comparer les deux versions.\n",
    "\n",
    "2) Appliquer FISTA √† ce m√™me probl√®me et r√©aliser le dashboard associ√©.\n",
    "\n",
    "3) R√©aliser un plan d'exp√©riences pour comparer les diff√©rents choix de param√®tres, uniquement pour la version FISTA. Il faut faire tr√®s attention ici car d√®s que le nombre d'it√©rations devient cons√©quent, chaque exp√©rience prend un temps non n√©gligeable. Assurez vous avant de lancer les XP num√©rique que le temps total est raisonnable.\n",
    "\n",
    "4) Comparer cette m√©thode en terme de PSNR, pour les valeurs optimales des param√®tres aux meilleurs m√©thodes par seuillage en ondelettes utilisant les translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pour aller plus loin (facultatif et √† titre d'information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plusieurs d√©finitions de la norme de variation totale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe plusieurs d√©finition de la norme de variation totale. Celle que nous utilisons ici est celle qui est aussi appel√©e anisotrope mais il existe aussi une variation totale isotrope :\n",
    "\n",
    "https://en.wikipedia.org/wiki/Total_variation_denoising\n",
    "\n",
    "L'utilisation la variation totale isotrope privil√©gie moins les axes horizontaux et verticaux. Ce choix induit des d√©faut qui sont plus homog√®ne en fonctions des directions. La diff√©rence entre les deux approches est particuli√®rement visible sur les coins des objet, ou sur les bords de disques.\n",
    "\n",
    "Pour passer en version isotrope, il faut changer de norme dans \\eqref{Primal} ainsi... la d√©finition de la boule $\\ell_\\infty$ et donc de la projection dans \\eqref{Dual} sont l√©g√®rement diff√©rentes.  \n",
    "\n",
    "Il faut savoir que cette petite finesse existe et bien √™tre au clair sur les normes que l'on manipule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D√©bruitages d'images couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut effectuer un d√©bruitage similaire des images couleurs en effectuant un d√©bruitage canal chromatique par canal chromatique. Mais il est aussi possible de travailler directement sur l'image couleur et de d√©finir une norme de variation totale directement sur les 3 canaux, en sommant en sommant en chaque pixel la norme du vecteur gradient √† 6 composantes (3 canaux, 2 directions). L'in√©tr√™t de faire un calcul joint de la norme du gradient est de rendre coh√©rents les trois canaux de couleurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## A retenir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous avez une descente de gradient ou un Forward-Backward √† impl√©menter, les acc√©l√©rations de Nesterov sont tr√®s souvent efficaces et il est toujours rentable de tester et m√™me de tester diff√©rentes valeurs de $a$. Il est √† noter toutefois que th√©oriquement sur des fonctions fortement convexes, pour l'algorithme FB, la suite de terme g√©n√©ral $F(x_n)-F(x^*)$ d√©croit au moins g√©om√©triquement ce qui n'est pas le cas de l'acc√©l√©ration de Nesterov pr√©sent√©e ici qui sont au mieux polynomiales.\n",
    "Dans la pratique, pour un nombre raisonnable d'it√©rations, m√™me dans ce cas, les acc√©l√©rations de Nesterov sont largement comp√©titives.\n",
    "Mais il en existe d'autres encore plus efficaces sp√©cifiquement d√©di√©s √† ce cas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
